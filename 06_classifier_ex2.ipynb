{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arabic 100k Reviews (Part 2): Classifier\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook is the second part of the Arabic 100k Reviews classification pipeline. Building on the preprocessing work from Part 1, we now focus on building and evaluating a text classification model to predict sentiment (Positive or Negative) from Arabic reviews. This notebook covers vectorization, model training, evaluation, and interpretation of results, demonstrating a complete end-to-end NLP classification pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Refer to the README.md for lab setup instructions\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Build a text classification model for Arabic sentiment analysis\n",
    "- Apply vectorization techniques (TF-IDF) to convert preprocessed text into numerical features\n",
    "- Train and evaluate a machine learning classifier (Logistic Regression)\n",
    "- Understand model evaluation metrics (accuracy, precision, recall, F1-score, confusion matrix)\n",
    "- Interpret classification results and analyze model performance\n",
    "- Recognize the importance of proper train/test splitting and data preprocessing\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. **Setup and Imports** - Installing dependencies and importing libraries\n",
    "2. **Data Loading** - Loading preprocessed data from Part 1\n",
    "3. **Text Analytics (EDA)** - Analyzing the preprocessed dataset\n",
    "4. **Vectorization** - Converting text to numerical features using TF-IDF\n",
    "5. **Model Training** - Training a Logistic Regression classifier\n",
    "6. **Model Evaluation** - Assessing performance with various metrics\n",
    "7. **Results Interpretation** - Understanding model predictions and errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal = pd.read_csv('ar_reviews_100k_cleaned.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=45, stop=51, step=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ids = df_normal.loc[45:50].index\n",
    "sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-460d4a9b-2235-4d19-823b-7a16d6620dce\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_words</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Negative</td>\n",
       "      <td>ضعيف. الانترنت. الفندق</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>ضعيف الانترنت الفندق</td>\n",
       "      <td>['ضعف', 'نرن', 'ندق']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Positive</td>\n",
       "      <td>جيد جدا. شكرا لكم.</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>جيد جدا شكرا لكم</td>\n",
       "      <td>['جيد', 'جدا', 'شكر']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Positive</td>\n",
       "      <td>رأيي في هذا الكتاب و جزئه الاول ما قاله مصطفي ...</td>\n",
       "      <td>115</td>\n",
       "      <td>23</td>\n",
       "      <td>رأيي في هذا الكتاب و جزئه الاول ما قاله مصطفي ...</td>\n",
       "      <td>['رأي', 'كتب', 'جزئ', 'اول', 'قله', 'صطف', 'حم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>حبيت اسلوب الكاتبه كتير وفي جزء كبير روحاني وح...</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>حبيت اسلوب الكاتبه كتير وفي جزء كبير روحاني وح...</td>\n",
       "      <td>['حبت', 'سلب', 'كتب', 'كتر', 'وفي', 'جزء', 'كب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>جيد . الفدق جيد. الوقع. الاستقبال مركز الخدمة</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>جيد الفدق جيد الوقع الاستقبال مركز الخدمة</td>\n",
       "      <td>['جيد', 'فدق', 'جيد', 'وقع', 'ركز', 'خدم']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>تقييمي . . مكتوب من ضمن الخيارات تقديم مشروب م...</td>\n",
       "      <td>102</td>\n",
       "      <td>20</td>\n",
       "      <td>تقييمي مكتوب من ضمن الخيارات تقديم مشروب مجاني...</td>\n",
       "      <td>['قيم', 'كتب', 'ضمن', 'خير', 'قدم', 'شرب', 'مج...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-460d4a9b-2235-4d19-823b-7a16d6620dce')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-460d4a9b-2235-4d19-823b-7a16d6620dce button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-460d4a9b-2235-4d19-823b-7a16d6620dce');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       label                                               text  num_chars  \\\n",
       "45  Negative                             ضعيف. الانترنت. الفندق         22   \n",
       "46  Positive                                 جيد جدا. شكرا لكم.         18   \n",
       "47  Positive  رأيي في هذا الكتاب و جزئه الاول ما قاله مصطفي ...        115   \n",
       "48     Mixed  حبيت اسلوب الكاتبه كتير وفي جزء كبير روحاني وح...         58   \n",
       "49     Mixed      جيد . الفدق جيد. الوقع. الاستقبال مركز الخدمة         45   \n",
       "50     Mixed  تقييمي . . مكتوب من ضمن الخيارات تقديم مشروب م...        102   \n",
       "\n",
       "    num_words                                         text_clean  \\\n",
       "45          3                               ضعيف الانترنت الفندق   \n",
       "46          4                                   جيد جدا شكرا لكم   \n",
       "47         23  رأيي في هذا الكتاب و جزئه الاول ما قاله مصطفي ...   \n",
       "48         10  حبيت اسلوب الكاتبه كتير وفي جزء كبير روحاني وح...   \n",
       "49          8          جيد الفدق جيد الوقع الاستقبال مركز الخدمة   \n",
       "50         20  تقييمي مكتوب من ضمن الخيارات تقديم مشروب مجاني...   \n",
       "\n",
       "                                       stemmed_tokens  \n",
       "45                              ['ضعف', 'نرن', 'ندق']  \n",
       "46                              ['جيد', 'جدا', 'شكر']  \n",
       "47  ['رأي', 'كتب', 'جزئ', 'اول', 'قله', 'صطف', 'حم...  \n",
       "48  ['حبت', 'سلب', 'كتب', 'كتر', 'وفي', 'جزء', 'كب...  \n",
       "49         ['جيد', 'فدق', 'جيد', 'وقع', 'ركز', 'خدم']  \n",
       "50  ['قيم', 'كتب', 'ضمن', 'خير', 'قدم', 'شرب', 'مج...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal.loc[sample_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analytics (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all of this, let's count the number of unique tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'\", 428696),\n",
       " (',', 205347),\n",
       " (' ', 205347),\n",
       " ('ر', 53548),\n",
       " ('ل', 48756),\n",
       " ('ا', 43960),\n",
       " ('م', 37622),\n",
       " ('ن', 34172),\n",
       " ('ي', 33837),\n",
       " ('د', 33724)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens = [item for sublist in df_normal['stemmed_tokens'] for item in sublist]\n",
    "token_counter = Counter(all_tokens)\n",
    "token_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Student** Exercise\n",
    "\n",
    "WHAT HAPPENED? WHY ARE WE GETTING THIS OUTPUT?:\n",
    "\n",
    "```\n",
    "[(\"'\", 428696),\n",
    " (',', 205347),\n",
    " (' ', 205347),\n",
    " ('ر', 53548),\n",
    " ('ل', 48756),\n",
    " ('ا', 43960),\n",
    " ('م', 37622),\n",
    " ('ن', 34172),\n",
    " ('ي', 33837),\n",
    " ('د', 33724)]\n",
    " ```\n",
    "\n",
    "> Your task is to fix the issue above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique words do we have now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique ratio: 0.00%\n"
     ]
    }
   ],
   "source": [
    "unique_ratio = len(token_counter) / len(all_tokens)\n",
    "print(f'Unique ratio: {unique_ratio:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out which words are associated with positive and negative labels, and which aren't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split counts based on labels\n",
    "counter_positive = Counter([item for sublist in df_normal.loc[df_normal['label'] == 'Positive', 'stemmed_tokens'] for item in sublist])\n",
    "counter_negative = Counter([item for sublist in df_normal.loc[df_normal['label'] == 'Negative', 'stemmed_tokens'] for item in sublist])\n",
    "counter_mixed = Counter([item for sublist in df_normal.loc[df_normal['label'] == 'Mixed', 'stemmed_tokens'] for item in sublist])\n",
    "\n",
    "# Purify each label\n",
    "## Positive\n",
    "pure_positive = counter_positive.copy()\n",
    "pure_positive.subtract(counter_negative)\n",
    "pure_positive.subtract(counter_mixed)\n",
    "\n",
    "## Negative\n",
    "pure_negative = counter_negative.copy()\n",
    "pure_negative.subtract(counter_positive)\n",
    "pure_negative.subtract(counter_mixed)\n",
    "\n",
    "## Neutral\n",
    "pure_mixed = counter_mixed.copy()\n",
    "pure_mixed.subtract(counter_positive)\n",
    "pure_mixed.subtract(counter_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_66e4b_row0_col1 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_66e4b_row1_col1 {\n",
       "  background-color: #00451c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_66e4b_row2_col1 {\n",
       "  background-color: #004c1e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_66e4b_row3_col1, #T_66e4b_row4_col1 {\n",
       "  background-color: #18823d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_66e4b_row5_col1 {\n",
       "  background-color: #289049;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_66e4b_row6_col1 {\n",
       "  background-color: #2c944c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_66e4b_row7_col1 {\n",
       "  background-color: #3aa357;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_66e4b_row8_col1 {\n",
       "  background-color: #53b466;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_66e4b_row9_col1 {\n",
       "  background-color: #5eb96b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_66e4b_row10_col1 {\n",
       "  background-color: #65bd6f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_66e4b_row11_col1, #T_66e4b_row12_col1 {\n",
       "  background-color: #8ed08b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_66e4b_row13_col1 {\n",
       "  background-color: #90d18d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_66e4b_row14_col1 {\n",
       "  background-color: #9cd797;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_66e4b_row15_col1 {\n",
       "  background-color: #b2e0ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_66e4b_row16_col1 {\n",
       "  background-color: #d6efd0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_66e4b_row17_col1 {\n",
       "  background-color: #e2f4dd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_66e4b_row18_col1 {\n",
       "  background-color: #e9f7e5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_66e4b_row19_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_66e4b\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_66e4b_level0_col0\" class=\"col_heading level0 col0\" >token</th>\n",
       "      <th id=\"T_66e4b_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_66e4b_row0_col0\" class=\"data row0 col0\" >إ</td>\n",
       "      <td id=\"T_66e4b_row0_col1\" class=\"data row0 col1\" >-113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_66e4b_row1_col0\" class=\"data row1 col0\" >آ</td>\n",
       "      <td id=\"T_66e4b_row1_col1\" class=\"data row1 col1\" >-136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_66e4b_row2_col0\" class=\"data row2 col0\" >ؤ</td>\n",
       "      <td id=\"T_66e4b_row2_col1\" class=\"data row2 col1\" >-243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_66e4b_row3_col0\" class=\"data row3 col0\" >ذ</td>\n",
       "      <td id=\"T_66e4b_row3_col1\" class=\"data row3 col1\" >-1172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_66e4b_row4_col0\" class=\"data row4 col0\" >ئ</td>\n",
       "      <td id=\"T_66e4b_row4_col1\" class=\"data row4 col1\" >-1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_66e4b_row5_col0\" class=\"data row5 col0\" >أ</td>\n",
       "      <td id=\"T_66e4b_row5_col1\" class=\"data row5 col1\" >-1475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_66e4b_row6_col0\" class=\"data row6 col0\" >ظ</td>\n",
       "      <td id=\"T_66e4b_row6_col1\" class=\"data row6 col1\" >-1560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_66e4b_row7_col0\" class=\"data row7 col0\" >ء</td>\n",
       "      <td id=\"T_66e4b_row7_col1\" class=\"data row7 col1\" >-1844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_66e4b_row8_col0\" class=\"data row8 col0\" >ز</td>\n",
       "      <td id=\"T_66e4b_row8_col1\" class=\"data row8 col1\" >-2223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_66e4b_row9_col0\" class=\"data row9 col0\" >ث</td>\n",
       "      <td id=\"T_66e4b_row9_col1\" class=\"data row9 col1\" >-2348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_66e4b_row10_col0\" class=\"data row10 col0\" >ة</td>\n",
       "      <td id=\"T_66e4b_row10_col1\" class=\"data row10 col1\" >-2435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_66e4b_row11_col0\" class=\"data row11 col0\" >[</td>\n",
       "      <td id=\"T_66e4b_row11_col1\" class=\"data row11 col1\" >-2987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_66e4b_row12_col0\" class=\"data row12 col0\" >]</td>\n",
       "      <td id=\"T_66e4b_row12_col1\" class=\"data row12 col1\" >-2987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_66e4b_row13_col0\" class=\"data row13 col0\" >ى</td>\n",
       "      <td id=\"T_66e4b_row13_col1\" class=\"data row13 col1\" >-2992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_66e4b_row14_col0\" class=\"data row14 col0\" >ض</td>\n",
       "      <td id=\"T_66e4b_row14_col1\" class=\"data row14 col1\" >-3177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_66e4b_row15_col0\" class=\"data row15 col0\" >غ</td>\n",
       "      <td id=\"T_66e4b_row15_col1\" class=\"data row15 col1\" >-3522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_66e4b_row16_col0\" class=\"data row16 col0\" >ط</td>\n",
       "      <td id=\"T_66e4b_row16_col1\" class=\"data row16 col1\" >-4172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_66e4b_row17_col0\" class=\"data row17 col0\" >ش</td>\n",
       "      <td id=\"T_66e4b_row17_col1\" class=\"data row17 col1\" >-4433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_66e4b_row18_col0\" class=\"data row18 col0\" >خ</td>\n",
       "      <td id=\"T_66e4b_row18_col1\" class=\"data row18 col1\" >-4632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66e4b_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_66e4b_row19_col0\" class=\"data row19 col0\" >ص</td>\n",
       "      <td id=\"T_66e4b_row19_col1\" class=\"data row19 col1\" >-5123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x79bfbb23fe00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    pure_positive.most_common(20),\n",
    "    columns=['token', 'count']\n",
    ").style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b14ce_row0_col1 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b14ce_row1_col1 {\n",
       "  background-color: #71020e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b14ce_row2_col1 {\n",
       "  background-color: #7a0510;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b14ce_row3_col1 {\n",
       "  background-color: #d42121;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b14ce_row4_col1 {\n",
       "  background-color: #de2b25;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b14ce_row5_col1 {\n",
       "  background-color: #e63328;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b14ce_row6_col1 {\n",
       "  background-color: #ed392b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b14ce_row7_col1 {\n",
       "  background-color: #ef3c2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b14ce_row8_col1 {\n",
       "  background-color: #f44d38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b14ce_row9_col1 {\n",
       "  background-color: #f96346;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b14ce_row10_col1 {\n",
       "  background-color: #fb694a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b14ce_row11_col1 {\n",
       "  background-color: #fc8060;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b14ce_row12_col1 {\n",
       "  background-color: #fc9070;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b14ce_row13_col1 {\n",
       "  background-color: #fc9d7f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b14ce_row14_col1 {\n",
       "  background-color: #fcbca2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b14ce_row15_col1, #T_b14ce_row16_col1 {\n",
       "  background-color: #fcbfa7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b14ce_row17_col1 {\n",
       "  background-color: #fed9c9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b14ce_row18_col1 {\n",
       "  background-color: #ffebe2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b14ce_row19_col1 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b14ce\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b14ce_level0_col0\" class=\"col_heading level0 col0\" >token</th>\n",
       "      <th id=\"T_b14ce_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b14ce_row0_col0\" class=\"data row0 col0\" >إ</td>\n",
       "      <td id=\"T_b14ce_row0_col1\" class=\"data row0 col1\" >-127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b14ce_row1_col0\" class=\"data row1 col0\" >آ</td>\n",
       "      <td id=\"T_b14ce_row1_col1\" class=\"data row1 col1\" >-212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b14ce_row2_col0\" class=\"data row2 col0\" >ؤ</td>\n",
       "      <td id=\"T_b14ce_row2_col1\" class=\"data row2 col1\" >-277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b14ce_row3_col0\" class=\"data row3 col0\" >ذ</td>\n",
       "      <td id=\"T_b14ce_row3_col1\" class=\"data row3 col1\" >-1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b14ce_row4_col0\" class=\"data row4 col0\" >ء</td>\n",
       "      <td id=\"T_b14ce_row4_col1\" class=\"data row4 col1\" >-1324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b14ce_row5_col0\" class=\"data row5 col0\" >أ</td>\n",
       "      <td id=\"T_b14ce_row5_col1\" class=\"data row5 col1\" >-1431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b14ce_row6_col0\" class=\"data row6 col0\" >ض</td>\n",
       "      <td id=\"T_b14ce_row6_col1\" class=\"data row6 col1\" >-1519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_b14ce_row7_col0\" class=\"data row7 col0\" >ظ</td>\n",
       "      <td id=\"T_b14ce_row7_col1\" class=\"data row7 col1\" >-1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_b14ce_row8_col0\" class=\"data row8 col0\" >ئ</td>\n",
       "      <td id=\"T_b14ce_row8_col1\" class=\"data row8 col1\" >-1722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_b14ce_row9_col0\" class=\"data row9 col0\" >غ</td>\n",
       "      <td id=\"T_b14ce_row9_col1\" class=\"data row9 col1\" >-1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_b14ce_row10_col0\" class=\"data row10 col0\" >ة</td>\n",
       "      <td id=\"T_b14ce_row10_col1\" class=\"data row10 col1\" >-2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_b14ce_row11_col0\" class=\"data row11 col0\" >ث</td>\n",
       "      <td id=\"T_b14ce_row11_col1\" class=\"data row11 col1\" >-2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_b14ce_row12_col0\" class=\"data row12 col0\" >ى</td>\n",
       "      <td id=\"T_b14ce_row12_col1\" class=\"data row12 col1\" >-2468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_b14ce_row13_col0\" class=\"data row13 col0\" >ز</td>\n",
       "      <td id=\"T_b14ce_row13_col1\" class=\"data row13 col1\" >-2607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_b14ce_row14_col0\" class=\"data row14 col0\" >خ</td>\n",
       "      <td id=\"T_b14ce_row14_col1\" class=\"data row14 col1\" >-2966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_b14ce_row15_col0\" class=\"data row15 col0\" >[</td>\n",
       "      <td id=\"T_b14ce_row15_col1\" class=\"data row15 col1\" >-3019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_b14ce_row16_col0\" class=\"data row16 col0\" >]</td>\n",
       "      <td id=\"T_b14ce_row16_col1\" class=\"data row16 col1\" >-3019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_b14ce_row17_col0\" class=\"data row17 col0\" >ط</td>\n",
       "      <td id=\"T_b14ce_row17_col1\" class=\"data row17 col1\" >-3342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_b14ce_row18_col0\" class=\"data row18 col0\" >ش</td>\n",
       "      <td id=\"T_b14ce_row18_col1\" class=\"data row18 col1\" >-3671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b14ce_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_b14ce_row19_col0\" class=\"data row19 col0\" >ص</td>\n",
       "      <td id=\"T_b14ce_row19_col1\" class=\"data row19 col1\" >-3905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x79bfb16024b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    pure_negative.most_common(20),\n",
    "    columns=['token', 'count']\n",
    ").style.background_gradient(cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_edaa3_row0_col1 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_edaa3_row1_col1 {\n",
       "  background-color: #08326e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_edaa3_row2_col1 {\n",
       "  background-color: #083877;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_edaa3_row3_col1 {\n",
       "  background-color: #2070b4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_edaa3_row4_col1 {\n",
       "  background-color: #3080bd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_edaa3_row5_col1 {\n",
       "  background-color: #3686c0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_edaa3_row6_col1 {\n",
       "  background-color: #3f8fc5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_edaa3_row7_col1 {\n",
       "  background-color: #4191c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_edaa3_row8_col1 {\n",
       "  background-color: #4695c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_edaa3_row9_col1 {\n",
       "  background-color: #57a0ce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_edaa3_row10_col1 {\n",
       "  background-color: #5ca4d0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_edaa3_row11_col1 {\n",
       "  background-color: #65aad4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_edaa3_row12_col1 {\n",
       "  background-color: #68acd5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_edaa3_row13_col1 {\n",
       "  background-color: #7cb7da;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_edaa3_row14_col1, #T_edaa3_row15_col1 {\n",
       "  background-color: #aed1e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_edaa3_row16_col1 {\n",
       "  background-color: #c7dcef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_edaa3_row17_col1 {\n",
       "  background-color: #cde0f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_edaa3_row18_col1 {\n",
       "  background-color: #dfecf7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_edaa3_row19_col1 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_edaa3\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_edaa3_level0_col0\" class=\"col_heading level0 col0\" >token</th>\n",
       "      <th id=\"T_edaa3_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_edaa3_row0_col0\" class=\"data row0 col0\" >آ</td>\n",
       "      <td id=\"T_edaa3_row0_col1\" class=\"data row0 col1\" >-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_edaa3_row1_col0\" class=\"data row1 col0\" >إ</td>\n",
       "      <td id=\"T_edaa3_row1_col1\" class=\"data row1 col1\" >-101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_edaa3_row2_col0\" class=\"data row2 col0\" >ؤ</td>\n",
       "      <td id=\"T_edaa3_row2_col1\" class=\"data row2 col1\" >-205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_edaa3_row3_col0\" class=\"data row3 col0\" >ذ</td>\n",
       "      <td id=\"T_edaa3_row3_col1\" class=\"data row3 col1\" >-1132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_edaa3_row4_col0\" class=\"data row4 col0\" >ظ</td>\n",
       "      <td id=\"T_edaa3_row4_col1\" class=\"data row4 col1\" >-1388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_edaa3_row5_col0\" class=\"data row5 col0\" >أ</td>\n",
       "      <td id=\"T_edaa3_row5_col1\" class=\"data row5 col1\" >-1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_edaa3_row6_col0\" class=\"data row6 col0\" >ث</td>\n",
       "      <td id=\"T_edaa3_row6_col1\" class=\"data row6 col1\" >-1654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_edaa3_row7_col0\" class=\"data row7 col0\" >ض</td>\n",
       "      <td id=\"T_edaa3_row7_col1\" class=\"data row7 col1\" >-1689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_edaa3_row8_col0\" class=\"data row8 col0\" >ء</td>\n",
       "      <td id=\"T_edaa3_row8_col1\" class=\"data row8 col1\" >-1748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_edaa3_row9_col0\" class=\"data row9 col0\" >غ</td>\n",
       "      <td id=\"T_edaa3_row9_col1\" class=\"data row9 col1\" >-1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_edaa3_row10_col0\" class=\"data row10 col0\" >ة</td>\n",
       "      <td id=\"T_edaa3_row10_col1\" class=\"data row10 col1\" >-2049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_edaa3_row11_col0\" class=\"data row11 col0\" >ى</td>\n",
       "      <td id=\"T_edaa3_row11_col1\" class=\"data row11 col1\" >-2158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_edaa3_row12_col0\" class=\"data row12 col0\" >ئ</td>\n",
       "      <td id=\"T_edaa3_row12_col1\" class=\"data row12 col1\" >-2206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_edaa3_row13_col0\" class=\"data row13 col0\" >ز</td>\n",
       "      <td id=\"T_edaa3_row13_col1\" class=\"data row13 col1\" >-2415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_edaa3_row14_col0\" class=\"data row14 col0\" >[</td>\n",
       "      <td id=\"T_edaa3_row14_col1\" class=\"data row14 col1\" >-2999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_edaa3_row15_col0\" class=\"data row15 col0\" >]</td>\n",
       "      <td id=\"T_edaa3_row15_col1\" class=\"data row15 col1\" >-2999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_edaa3_row16_col0\" class=\"data row16 col0\" >ط</td>\n",
       "      <td id=\"T_edaa3_row16_col1\" class=\"data row16 col1\" >-3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_edaa3_row17_col0\" class=\"data row17 col0\" >خ</td>\n",
       "      <td id=\"T_edaa3_row17_col1\" class=\"data row17 col1\" >-3498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_edaa3_row18_col0\" class=\"data row18 col0\" >ص</td>\n",
       "      <td id=\"T_edaa3_row18_col1\" class=\"data row18 col1\" >-3917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_edaa3_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_edaa3_row19_col0\" class=\"data row19 col0\" >ش</td>\n",
       "      <td id=\"T_edaa3_row19_col1\" class=\"data row19 col1\" >-4433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x79bfb1602480>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the neutral words that are not in the positive or negative\n",
    "pd.DataFrame(\n",
    "    pure_mixed.most_common(20),\n",
    "    columns=['token', 'count']\n",
    ").style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6b475b04-08d9-46c8-b9d9-085d5586b9e6\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_words</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Negative</td>\n",
       "      <td>ضعيف. الانترنت. الفندق</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>ضعيف الانترنت الفندق</td>\n",
       "      <td>['ضعف', 'نرن', 'ندق']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Positive</td>\n",
       "      <td>جيد جدا. شكرا لكم.</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>جيد جدا شكرا لكم</td>\n",
       "      <td>['جيد', 'جدا', 'شكر']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Positive</td>\n",
       "      <td>رأيي في هذا الكتاب و جزئه الاول ما قاله مصطفي ...</td>\n",
       "      <td>115</td>\n",
       "      <td>23</td>\n",
       "      <td>رأيي في هذا الكتاب و جزئه الاول ما قاله مصطفي ...</td>\n",
       "      <td>['رأي', 'كتب', 'جزئ', 'اول', 'قله', 'صطف', 'حم...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>حبيت اسلوب الكاتبه كتير وفي جزء كبير روحاني وح...</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>حبيت اسلوب الكاتبه كتير وفي جزء كبير روحاني وح...</td>\n",
       "      <td>['حبت', 'سلب', 'كتب', 'كتر', 'وفي', 'جزء', 'كب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>جيد . الفدق جيد. الوقع. الاستقبال مركز الخدمة</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>جيد الفدق جيد الوقع الاستقبال مركز الخدمة</td>\n",
       "      <td>['جيد', 'فدق', 'جيد', 'وقع', 'ركز', 'خدم']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Mixed</td>\n",
       "      <td>تقييمي . . مكتوب من ضمن الخيارات تقديم مشروب م...</td>\n",
       "      <td>102</td>\n",
       "      <td>20</td>\n",
       "      <td>تقييمي مكتوب من ضمن الخيارات تقديم مشروب مجاني...</td>\n",
       "      <td>['قيم', 'كتب', 'ضمن', 'خير', 'قدم', 'شرب', 'مج...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b475b04-08d9-46c8-b9d9-085d5586b9e6')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-6b475b04-08d9-46c8-b9d9-085d5586b9e6 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-6b475b04-08d9-46c8-b9d9-085d5586b9e6');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       label                                               text  num_chars  \\\n",
       "45  Negative                             ضعيف. الانترنت. الفندق         22   \n",
       "46  Positive                                 جيد جدا. شكرا لكم.         18   \n",
       "47  Positive  رأيي في هذا الكتاب و جزئه الاول ما قاله مصطفي ...        115   \n",
       "48     Mixed  حبيت اسلوب الكاتبه كتير وفي جزء كبير روحاني وح...         58   \n",
       "49     Mixed      جيد . الفدق جيد. الوقع. الاستقبال مركز الخدمة         45   \n",
       "50     Mixed  تقييمي . . مكتوب من ضمن الخيارات تقديم مشروب م...        102   \n",
       "\n",
       "    num_words                                         text_clean  \\\n",
       "45          3                               ضعيف الانترنت الفندق   \n",
       "46          4                                   جيد جدا شكرا لكم   \n",
       "47         23  رأيي في هذا الكتاب و جزئه الاول ما قاله مصطفي ...   \n",
       "48         10  حبيت اسلوب الكاتبه كتير وفي جزء كبير روحاني وح...   \n",
       "49          8          جيد الفدق جيد الوقع الاستقبال مركز الخدمة   \n",
       "50         20  تقييمي مكتوب من ضمن الخيارات تقديم مشروب مجاني...   \n",
       "\n",
       "                                       stemmed_tokens  \n",
       "45                              ['ضعف', 'نرن', 'ندق']  \n",
       "46                              ['جيد', 'جدا', 'شكر']  \n",
       "47  ['رأي', 'كتب', 'جزئ', 'اول', 'قله', 'صطف', 'حم...  \n",
       "48  ['حبت', 'سلب', 'كتب', 'كتر', 'وفي', 'جزء', 'كب...  \n",
       "49         ['جيد', 'فدق', 'جيد', 'وقع', 'ركز', 'خدم']  \n",
       "50  ['قيم', 'كتب', 'ضمن', 'خير', 'قدم', 'شرب', 'مج...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal.loc[sample_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Text Classification\n",
    "\n",
    "Now that we have cleaned and preprocessed our text data, we can build a **text classifier** that predicts the sentiment (Positive, Negative, or Mixed) of Arabic reviews.\n",
    "\n",
    "**What is Text Classification?**\n",
    "\n",
    "Text classification is a supervised machine learning task where we:\n",
    "1. **Extract features** from text (convert text to numbers)\n",
    "2. **Train a model** to learn patterns between features and labels\n",
    "3. **Predict** the class of new, unseen text\n",
    "\n",
    "**Why use word counts?**\n",
    "\n",
    "After cleaning and preprocessing, we have a list of tokens (words) for each review. One simple but effective approach is to:\n",
    "- Count how many times each word appears in each document\n",
    "- Use these counts as features for our classifier\n",
    "- This is called **Bag of Words (BoW)** representation\n",
    "\n",
    "**The Bag of Words Model:**\n",
    "\n",
    "The Bag of Words model represents text as a vector of word counts, ignoring word order and grammar. For example:\n",
    "\n",
    "- Review 1: \"ممتاز رائع\" → `{\"ممتاز\": 1, \"رائع\": 1}`\n",
    "- Review 2: \"ممتاز ممتاز سيء\" → `{\"ممتاز\": 2, \"رائع\": 0, \"سيء\": 1}`\n",
    "\n",
    "This creates a feature matrix where:\n",
    "- Each row = one review\n",
    "- Each column = one unique word in the vocabulary\n",
    "- Each cell = count of that word in that review\n",
    "\n",
    "**Why this works:**\n",
    "\n",
    "From our EDA, we saw that certain words are more associated with positive reviews (e.g., \"ممتاز\", \"رائع\") and others with negative reviews (e.g., \"سيء\", \"ضعيف\"). A classifier can learn these patterns from the word counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Prepare Text Data for Feature Extraction\n",
    "\n",
    "Our `stemmed_tokens` column contains lists of tokens. To use scikit-learn's `CountVectorizer`, we need to convert these token lists back into text strings (space-separated words).\n",
    "\n",
    "**Why convert back to strings?**\n",
    "\n",
    "- `CountVectorizer` expects text input (strings)\n",
    "- It will handle tokenization internally, but since we've already cleaned and stemmed our text, we want to use our preprocessed tokens\n",
    "- We'll join the tokens with spaces to create clean text strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "ضعيف. الانترنت. الفندق\n",
      "\n",
      "Cleaned and processed text:\n",
      "[ ' ض ع ف ' ,   ' ن ر ن ' ,   ' ن د ق ' ]\n",
      "\n",
      "Tokens used:\n",
      "['ضعف', 'ن\n"
     ]
    }
   ],
   "source": [
    "# Convert token lists back to space-separated strings\n",
    "# This allows CountVectorizer to work with our preprocessed tokens\n",
    "df_normal['text_processed'] = df_normal['stemmed_tokens'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "# Display a sample to verify\n",
    "print(\"Original text:\")\n",
    "print(df_normal.loc[sample_ids[0], 'text'])\n",
    "print(\"\\nCleaned and processed text:\")\n",
    "print(df_normal.loc[sample_ids[0], 'text_processed'])\n",
    "print(\"\\nTokens used:\")\n",
    "print(df_normal.loc[sample_ids[0], 'stemmed_tokens'][:10])  # Show first 10 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Word Count Features\n",
    "\n",
    "We'll use scikit-learn's `CountVectorizer` to convert our processed text into a matrix of word counts.\n",
    "\n",
    "**Key parameters:**\n",
    "- `max_features`: Limit vocabulary size to the most frequent N words (reduces dimensionality)\n",
    "- `min_df`: Ignore words that appear in fewer than N documents (removes rare words)\n",
    "- `max_df`: Ignore words that appear in more than N% of documents (removes common words that appear everywhere)\n",
    "\n",
    "**Why limit features?**\n",
    "- Reduces memory usage\n",
    "- Speeds up training\n",
    "- Can improve generalization by focusing on meaningful words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1185414694.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Transform text to word count matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# This creates a sparse matrix where each row is a review and each column is a word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_normal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_processed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_normal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1374\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1376\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1280\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1283\u001b[0m                     \u001b[0;34m\"empty vocabulary; perhaps the documents only contain stop words\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 )\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "# Create CountVectorizer (Bag of Words)\n",
    "# We use max_features to limit vocabulary size for efficiency\n",
    "# min_df=2 means words must appear in at least 2 documents\n",
    "vectorizer = CountVectorizer(\n",
    "    max_features=5000,  # Use top 5000 most frequent words\n",
    "    min_df=2,           # Word must appear in at least 2 documents\n",
    "    max_df=0.95         # Ignore words that appear in >95% of documents\n",
    ")\n",
    "\n",
    "# Transform text to word count matrix\n",
    "# This creates a sparse matrix where each row is a review and each column is a word\n",
    "X = vectorizer.fit_transform(df_normal['text_processed'])\n",
    "y = df_normal['label'].values\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Number of reviews: {X.shape[0]}\")\n",
    "print(f\"Number of features (words): {X.shape[1]}\")\n",
    "print(f\"Labels: {np.unique(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding the Feature Matrix:**\n",
    "\n",
    "The `X` matrix is sparse (mostly zeros) because:\n",
    "- Each review contains only a small subset of all possible words\n",
    "- Most words don't appear in most reviews\n",
    "- This is normal and expected for text data\n",
    "\n",
    "Let's visualize what the feature matrix looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse matrix to dense for visualization (only for small samples!)\n",
    "# Note: For large datasets, keep it sparse to save memory\n",
    "X_sample = X[:5].toarray()\n",
    "\n",
    "# Get feature names (words)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "df_features = pd.DataFrame(\n",
    "    X_sample,\n",
    "    columns=feature_names,\n",
    "    index=[f\"Review {i+1}\" for i in range(5)]\n",
    ")\n",
    "\n",
    "# Show only columns (words) that appear in these 5 reviews\n",
    "non_zero_cols = df_features.columns[df_features.sum() > 0]\n",
    "print(f\"Showing {len(non_zero_cols)} words that appear in the first 5 reviews:\")\n",
    "display(df_features[non_zero_cols[:20]])  # Show first 20 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Split Data into Training and Testing Sets\n",
    "\n",
    "**Why split the data?**\n",
    "\n",
    "We need to:\n",
    "1. **Train** the model on one portion of data\n",
    "2. **Test** the model on unseen data to evaluate its performance\n",
    "3. **Prevent overfitting** - ensure the model generalizes to new data\n",
    "\n",
    "**Important:** We split AFTER preprocessing to avoid data leakage (information from test set influencing training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data: 80% training, 20% testing\n",
    "# stratify=y ensures same class distribution in both sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=y  # Maintain class balance\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} reviews\")\n",
    "print(f\"Test set: {X_test.shape[0]} reviews\")\n",
    "print(\"\\nTraining label distribution:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(\"\\nTest label distribution:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train a Classifier\n",
    "\n",
    "We'll use a **Logistic Regression** classifier, which is:\n",
    "- **Fast** and efficient for text classification\n",
    "- **Well-suited** for count-based features (like our word counts)\n",
    "- **Simple** to understand and interpret\n",
    "- **Effective** for text classification tasks\n",
    "- **Provides probability estimates** for each class\n",
    "\n",
    "**How Logistic Regression works (simplified):**\n",
    "1. Learns weights for each feature (word) that indicate its importance for each class\n",
    "2. Uses a logistic function to convert weighted sums into probabilities\n",
    "3. Predicts the class with highest probability\n",
    "\n",
    "Logistic Regression is a linear classifier that works well with sparse, high-dimensional text features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the classifier\n",
    "# max_iter=1000 ensures convergence for large datasets\n",
    "classifier = LogisticRegression(max_iter=1000, random_state=SEED)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"Classifier trained successfully!\")\n",
    "print(f\"Number of features learned: {classifier.coef_.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate the Classifier\n",
    "\n",
    "Now let's evaluate how well our classifier performs on the test set. We'll use several metrics:\n",
    "\n",
    "- **Accuracy**: Overall percentage of correct predictions\n",
    "- **Precision**: Of all predictions for a class, how many were correct?\n",
    "- **Recall**: Of all actual instances of a class, how many did we find?\n",
    "- **F1-Score**: Harmonic mean of precision and recall (balances both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.2%}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Detailed Classification Report:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding the Classification Report:**\n",
    "\n",
    "- **Precision**: When the model predicts a class, how often is it correct?\n",
    "  - High precision = few false positives\n",
    "  \n",
    "- **Recall**: How many of the actual instances of a class did we catch?\n",
    "  - High recall = few false negatives\n",
    "  \n",
    "- **F1-Score**: Balances precision and recall\n",
    "  - Useful when you need a single metric\n",
    "  \n",
    "- **Support**: Number of actual instances of each class in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix for visualization\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Display as DataFrame for better readability\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[f\"Actual {label}\" for label in classifier.classes_],\n",
    "    columns=[f\"Predicted {label}\" for label in classifier.classes_]\n",
    ")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"(Rows = Actual, Columns = Predicted)\")\n",
    "display(cm_df)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classifier.classes_))\n",
    "plt.xticks(tick_marks, classifier.classes_, rotation=45)\n",
    "plt.yticks(tick_marks, classifier.classes_)\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "\n",
    "# Add text annotations\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in np.ndindex(cm.shape):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the Confusion Matrix:**\n",
    "\n",
    "- **Diagonal elements** (top-left to bottom-right): Correct predictions\n",
    "- **Off-diagonal elements**: Misclassifications\n",
    "  - Example: If \"Actual Negative\" row has a number in \"Predicted Positive\" column, those are negative reviews incorrectly classified as positive\n",
    "\n",
    "The confusion matrix helps us understand:\n",
    "- Which classes are confused with each other\n",
    "- Whether errors are balanced or biased toward certain classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Analyze Important Features\n",
    "\n",
    "Let's see which words are most important for each class. This helps us understand what the model learned and provides interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names (words)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Get coefficients for each class\n",
    "# Higher values = more indicative of that class\n",
    "coefficients = classifier.coef_\n",
    "\n",
    "# Create DataFrame showing top words for each class\n",
    "top_words_per_class = {}\n",
    "for idx, class_label in enumerate(classifier.classes_):\n",
    "    # Get indices of top words for this class\n",
    "    top_indices = np.argsort(coefficients[idx])[-20:][::-1]  # Top 20 words\n",
    "    top_words = [(feature_names[i], coefficients[idx][i]) for i in top_indices]\n",
    "    top_words_per_class[class_label] = top_words\n",
    "\n",
    "# Display results\n",
    "for class_label, words in top_words_per_class.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Top 20 words for class: {class_label}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    df_top = pd.DataFrame(words, columns=['Word', 'Coefficient']).style.background_gradient(cmap='Greens')\n",
    "    display(df_top.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpreting Feature Importance:**\n",
    "\n",
    "The coefficients tell us how strongly each word is associated with each class:\n",
    "- **Higher coefficient** = word is more indicative of that class\n",
    "- **Lower (more negative) coefficient** = word is less indicative of that class\n",
    "- Words with high coefficients for \"Positive\" are likely positive sentiment words\n",
    "- Words with high coefficients for \"Negative\" are likely negative sentiment words\n",
    "\n",
    "**Compare with EDA results:** Do these top words match the words we found in our earlier EDA analysis? This validates that the model learned meaningful patterns!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Test on Sample Reviews\n",
    "\n",
    "Let's test our classifier on some example reviews to see it in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test indices in the original dataframe\n",
    "# train_test_split maintains order, so we need to track which rows went to test set\n",
    "_, test_indices_original = train_test_split(\n",
    "    df_normal.index,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=df_normal['label']\n",
    ")\n",
    "\n",
    "# Select a few random test examples\n",
    "np.random.seed(SEED)\n",
    "# FIX: For sparse matrices, use shape[0] instead of len()\n",
    "sample_test_indices = np.random.choice(X_test.shape[0], size=5, replace=False)\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# For a more visual display, let's build a table of predictions and use color to show confidence\n",
    "\n",
    "viz_rows = []\n",
    "for test_idx in sample_test_indices:\n",
    "    original_df_idx = test_indices_original[test_idx]\n",
    "    text_snippet = df_normal.loc[original_df_idx, 'text'][:80] + (\"...\" if len(df_normal.loc[original_df_idx, 'text']) > 80 else \"\")\n",
    "    actual = y_test[test_idx]\n",
    "    prediction = classifier.predict(X_test[test_idx:test_idx+1])[0]\n",
    "    probs = classifier.predict_proba(X_test[test_idx:test_idx+1])[0]\n",
    "    confidence = probs[classifier.classes_.tolist().index(prediction)]\n",
    "    viz_rows.append({\n",
    "        \"Review #\": test_idx,\n",
    "        \"Snippet\": text_snippet,\n",
    "        \"Actual Label\": actual,\n",
    "        \"Predicted Label\": prediction,\n",
    "        \"Confidence\": confidence,\n",
    "        **{f\"P({cls})\": p for cls, p in zip(classifier.classes_, probs)}\n",
    "    })\n",
    "\n",
    "viz_df = pd.DataFrame(viz_rows)\n",
    "# True-match in green, wrong in red\n",
    "def highlight_prediction(row):\n",
    "    color = \"\"\n",
    "    if row['Actual Label'] == row['Predicted Label']:\n",
    "        color = \"background-color: #d4f4dd\"  # light green\n",
    "    else:\n",
    "        color = \"background-color: #f4cccc\"  # light red\n",
    "    return [color]*len(row)\n",
    "# Display styled table, coloring accuracy and using a confidence gradient on \"Confidence\"\n",
    "viz_df_styled = (viz_df.style\n",
    "    .apply(highlight_prediction, axis=1)\n",
    "    .background_gradient(subset=['Confidence'], cmap='Blues')\n",
    "    .format({col: \"{:.2%}\" for col in ['Confidence'] + [f\"P({cls})\" for cls in classifier.classes_]})\n",
    ")\n",
    "display(viz_df_styled)\n",
    "\n",
    "# Also, show barplots of the predicted probability for each review\n",
    "for idx, row in viz_df.iterrows():\n",
    "    plt.figure(figsize=(4,2))\n",
    "    plt.bar(classifier.classes_, [row[f\"P({cls})\"] for cls in classifier.classes_], color=['#d1e0e0' if row['Predicted Label']==cls else '#ffe0b2' for cls in classifier.classes_])\n",
    "    plt.title(f\"Review #{row['Review #']} prediction\\nActual: {row['Actual Label']} | Predicted: {row['Predicted Label']} ({row['Confidence']:.0%})\")\n",
    "    plt.ylabel('Probability')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary: What We Learned\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "- **Simple approaches work**: Word counts (Bag of Words) can be effective for text classification\n",
    "- **Preprocessing matters**: The cleaning, normalization, and stemming we did earlier improved our features\n",
    "- **Interpretability**: We can see which words drive predictions, making the model explainable\n",
    "- **Evaluation is crucial**: Always test on unseen data to measure real-world performance\n",
    "\n",
    "**Next Steps (for future exploration):**\n",
    "\n",
    "- Try **TF-IDF** instead of raw counts (weights words by importance)\n",
    "- Experiment with different classifiers (SVM, Random Forest, etc.)\n",
    "- Use **word embeddings** (like Word2Vec or pre-trained embeddings) for richer features\n",
    "- Fine-tune **transformer models** (like BERT) for state-of-the-art performance\n",
    "\n",
    "---\n",
    "\n",
    "**Remember**: This is a foundational approach. Modern NLP often uses more sophisticated methods, but understanding word counts and simple classifiers is essential for building intuition about how text classification works!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
